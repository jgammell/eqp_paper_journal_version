\begin{thebibliography}{32}
\providecommand{\natexlab}[1]{#1}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi:\discretionary{}{}{}#1}\else
  \providecommand{\doi}{doi:\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi
\providecommand{\selectlanguage}[1]{\relax}
\providecommand{\bibAnnoteFile}[1]{%
  \IfFileExists{#1}{\begin{quotation}\noindent\textsc{Key:} #1\\
  \textsc{Annotation:}\ \input{#1}\end{quotation}}{}}
\providecommand{\bibAnnote}[2]{%
  \begin{quotation}\noindent\textsc{Key:} #1\\
  \textsc{Annotation:}\ #2\end{quotation}}

\bibitem[{Bartunov et~al.(2018)Bartunov, Santoro, Richards, Hinton, and
  Lillicrap}]{bartunov2018}
Bartunov, S., Santoro, A., Richards, B.~A., Hinton, G.~E., and Lillicrap, T.~P.
  (2018).
\newblock Assessing the scalability of biologically-motivated deep learning
  algorithms and architectures.
\newblock \emph{CoRR} abs/1807.04587
\bibAnnoteFile{bartunov2018}

\bibitem[{Bengio et~al.(2015)Bengio, Lee, Bornschein, and Lin}]{bengio2015}
Bengio, Y., Lee, D., Bornschein, J., and Lin, Z. (2015).
\newblock Towards biologically plausible deep learning.
\newblock \emph{CoRR} abs/1502.04156
\bibAnnoteFile{bengio2015}

\bibitem[{Bullmore and Sporns(2009)}]{bullmore2009}
Bullmore, E. and Sporns, O. (2009).
\newblock Complex brain networks: graph theoretical analysis of structural and
  functional systems.
\newblock \emph{Nature}
\bibAnnoteFile{bullmore2009}

\bibitem[{Crafton et~al.(2019)Crafton, Parihar, Gebhardt, and
  Raychowdhury}]{crafton2019}
Crafton, B., Parihar, A., Gebhardt, E., and Raychowdhury, A. (2019).
\newblock Direct feedback alignment with sparse connections for local learning.
\newblock \emph{CoRR} abs/1903.02083
\bibAnnoteFile{crafton2019}

\bibitem[{Davies et~al.(2018)Davies, Srinivasa, Lin, Chinya, Joshi, Lines
  et~al.}]{davies2018}
Davies, M., Srinivasa, N., Lin, T.-H., Chinya, G., Joshi, P., Lines, A., et~al.
  (2018).
\newblock Loihi: A neuromorphic manycore processor with on-chip learning.
\newblock \emph{IEEE Micro} PP, 1--1.
\newblock \doi{10.1109/MM.2018.112130359}
\bibAnnoteFile{davies2018}

\bibitem[{Ernoult et~al.(2020)Ernoult, Grollier, Querlioz, Bengio, and
  Scellier}]{ernoult2020}
Ernoult, M., Grollier, J., Querlioz, D., Bengio, Y., and Scellier, B. (2020).
\newblock Equilibrium propagation with continual weight updates
\bibAnnoteFile{ernoult2020}

\bibitem[{Glorot and Bengio(2010)}]{glorot2010}
Glorot, X. and Bengio, Y. (2010).
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, eds. Y.~W. Teh and M.~Titterington
  (Chia Laguna Resort, Sardinia, Italy: PMLR), vol.~9 of \emph{Proceedings of
  Machine Learning Research}, 249--256
\bibAnnoteFile{glorot2010}

\bibitem[{He et~al.(2015)He, Zhang, Ren, and Sun}]{he2015}
He, K., Zhang, X., Ren, S., and Sun, J. (2015).
\newblock Deep residual learning for image recognition.
\newblock \emph{CoRR} abs/1512.03385
\bibAnnoteFile{he2015}

\bibitem[{Hopfield(1984)}]{hopfield1984}
Hopfield, J. (1984).
\newblock Neurons with graded response have collective computational properties
  like those of two-state neurons.
\newblock \emph{Proceedings of the National Academy of Sciences of the United
  States of America} 81, 3088--92.
\newblock \doi{10.1073/pnas.81.10.3088}
\bibAnnoteFile{hopfield1984}

\bibitem[{Indiveri et~al.(2011)Indiveri, Linares-Barranco, Hamilton, van
  Schaik, Etienne-Cummings, Delbruck et~al.}]{indiveri2011}
Indiveri, G., Linares-Barranco, B., Hamilton, T., van Schaik, A.,
  Etienne-Cummings, R., Delbruck, T., et~al. (2011).
\newblock Neuromorphic silicon neuron circuits.
\newblock \emph{Frontiers in Neuroscience} 5, 73.
\newblock \doi{10.3389/fnins.2011.00073}
\bibAnnoteFile{indiveri2011}

\bibitem[{Ioffe and Szegedy(2015)}]{ioffe2015}
Ioffe, S. and Szegedy, C. (2015).
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{CoRR} abs/1502.03167
\bibAnnoteFile{ioffe2015}

\bibitem[{Krishnan et~al.(2019)Krishnan, Du, and Cao}]{krishnan2019}
Krishnan, G., Du, X., and Cao, Y. (2019).
\newblock Structural pruning in deep neural networks: A small-world approach
\bibAnnoteFile{krishnan2019}

\bibitem[{LeCun and Cortes(1998)}]{mnist1998}
[Dataset] LeCun, Y. and Cortes, C. (1998).
\newblock The mnist database of handwritten digits
\bibAnnoteFile{mnist1998}

\bibitem[{Lee et~al.(2015)Lee, Zhang, Fischer, and Bengio}]{lee2015}
Lee, D.-H., Zhang, S., Fischer, A., and Bengio, Y. (2015).
\newblock Difference target propagation.
\newblock 498--515.
\newblock \doi{10.1007/978-3-319-23528-8_31}
\bibAnnoteFile{lee2015}

\bibitem[{Lillicrap et~al.(2014)Lillicrap, Cownden, Tweed, and
  Akerman}]{lillicrap2014}
Lillicrap, T.~P., Cownden, D., Tweed, D.~B., and Akerman, C.~J. (2014).
\newblock Random feedback weights support learning in deep neural networks
\bibAnnoteFile{lillicrap2014}

\bibitem[{Nahmias et~al.(2013)Nahmias, Shastri, Tait, and
  Prucnal}]{nahmias2013}
Nahmias, M., Shastri, B., Tait, A., and Prucnal, P. (2013).
\newblock A leaky integrate-and-fire laser neuron for ultrafast cognitive
  computing.
\newblock \emph{Selected Topics in Quantum Electronics, IEEE Journal of} 19,
  1--12.
\newblock \doi{10.1109/JSTQE.2013.2257700}
\bibAnnoteFile{nahmias2013}

\bibitem[{Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan
  et~al.}]{pytorch2019}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., et~al.
  (2019).
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, eds.
  H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett (Curran Associates, Inc.). 8024--8035
\bibAnnoteFile{pytorch2019}

\bibitem[{Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel,
  Thirion, Grisel et~al.}]{sklearn2011}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., et~al. (2011).
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research} 12, 2825--2830
\bibAnnoteFile{sklearn2011}

\bibitem[{Pedroni et~al.(2019)Pedroni, Joshi, Deiss, Sheik, Detorakis, Paul
  et~al.}]{pedroni2019}
Pedroni, B.~U., Joshi, S., Deiss, S.~R., Sheik, S., Detorakis, G., Paul, S.,
  et~al. (2019).
\newblock Memory-efficient synaptic connectivity for spike-timing- dependent
  plasticity.
\newblock \emph{Frontiers in Neuroscience} 13, 357.
\newblock \doi{10.3389/fnins.2019.00357}
\bibAnnoteFile{pedroni2019}

\bibitem[{Pineda(1987)}]{pineda1987}
Pineda, F. (1987).
\newblock Generalization of back-propagation to recurrent neural networks.
\newblock \emph{Physical Review Letters} 59, 2229--2232
\bibAnnoteFile{pineda1987}

\bibitem[{Scellier and Bengio(2016)}]{scellier17}
Scellier, B. and Bengio, Y. (2016).
\newblock Equilibrium propagation: Bridging the gap between energy-based models
  and backpropagation
\bibAnnoteFile{scellier17}

\bibitem[{Schemmel et~al.(2010)Schemmel, Br{\"u}derle, Gr{\"u}bl, Hock, Meier,
  and Millner}]{schemmel2010}
Schemmel, J., Br{\"u}derle, D., Gr{\"u}bl, A., Hock, M., Meier, K., and
  Millner, S. (2010).
\newblock A wafer-scale neuromorphic hardware system for large-scale neural
  modeling.
\newblock \emph{Proceedings of 2010 IEEE International Symposium on Circuits
  and Systems} , 1947--1950
\bibAnnoteFile{schemmel2010}

\bibitem[{Schmidhuber(2015)}]{schmidhuber2015}
Schmidhuber, J. (2015).
\newblock Deep learning in neural networks: An overview.
\newblock \emph{Neural Networks} 61, 85â€“117.
\newblock \doi{10.1016/j.neunet.2014.09.003}
\bibAnnoteFile{schmidhuber2015}

\bibitem[{{Shainline} et~al.(2019){Shainline}, {Buckley}, {McCaughan},
  {Chiles}, {Jafari Salim}, {Castellanos-Beltran} et~al.}]{shainline2019}
{Shainline}, J.~M., {Buckley}, S.~M., {McCaughan}, A.~N., {Chiles}, J.~T.,
  {Jafari Salim}, A., {Castellanos-Beltran}, M., et~al. (2019).
\newblock {Superconducting optoelectronic loop neurons}.
\newblock \emph{Journal of Applied Physics} 126, 044902.
\newblock \doi{10.1063/1.5096403}
\bibAnnoteFile{shainline2019}

\bibitem[{Simonyan and Zisserman(2014)}]{simonyan2014}
Simonyan, K. and Zisserman, A. (2014).
\newblock Very deep convolutional networks for large-scale image recognition
\bibAnnoteFile{simonyan2014}

\bibitem[{Srivastava et~al.(2015{\natexlab{a}})Srivastava, Greff, and
  Schmidhuber}]{srivastava2015}
Srivastava, R.~K., Greff, K., and Schmidhuber, J. (2015{\natexlab{a}}).
\newblock Highway networks.
\newblock \emph{CoRR} abs/1505.00387
\bibAnnoteFile{srivastava2015}

\bibitem[{Srivastava et~al.(2015{\natexlab{b}})Srivastava, Greff, and
  Schmidhuber}]{srivastava2015tvdn}
Srivastava, R.~K., Greff, K., and Schmidhuber, J. (2015{\natexlab{b}}).
\newblock Training very deep networks
\bibAnnoteFile{srivastava2015tvdn}

\bibitem[{Watts and Strogatz(1998)}]{watts98}
Watts, D. and Strogatz, S. (1998).
\newblock Collective dynamics of 'small-world' networks.
\newblock \emph{Nature}
\bibAnnoteFile{watts98}

\bibitem[{Wozniak et~al.(2018)Wozniak, Pantazi, and Eleftheriou}]{wozniak2018}
Wozniak, S., Pantazi, A., and Eleftheriou, E. (2018).
\newblock Deep networks incorporating spiking neural dynamics.
\newblock \emph{CoRR} abs/1812.07040
\bibAnnoteFile{wozniak2018}

\bibitem[{Xiao et~al.(2017)Xiao, Rasul, and Vollgraf}]{fmnist2017}
[Dataset] Xiao, H., Rasul, K., and Vollgraf, R. (2017).
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms
\bibAnnoteFile{fmnist2017}

\bibitem[{Xiaohu et~al.(2011)Xiaohu, Xiaoling, Jinhua, Yulin, and
  Maolin}]{xiaohu2011}
Xiaohu, L., Xiaoling, L., Jinhua, Z., Yulin, Z., and Maolin, L. (2011).
\newblock A new multilayer feedforward small-world neural network with its
  performances on function approximation.
\newblock In \emph{2011 IEEE International Conference on Computer Science and
  Automation Engineering}
\bibAnnoteFile{xiaohu2011}

\bibitem[{Xie and Seung(2003)}]{xie2003}
Xie, X. and Seung, H. (2003).
\newblock Equivalence of backpropagation and contrastive hebbian learning in a
  layered network.
\newblock \emph{Neural computation} 15, 441--54.
\newblock \doi{10.1162/089976603762552988}
\bibAnnoteFile{xie2003}

\end{thebibliography}
